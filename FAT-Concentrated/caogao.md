This paper is an overview of the methods to improve the robustness of federated learning models, in order to improve the credibility and security of federated learning. Before our review, there are some previous work on the security of federal learning, but they generally focus on the privacy leakage of federal learning or only focus on backdoor attacks. There are few studies and reports on adversarial attacks. On the basis of their work, this paper summarizes the attacks and defense methods of adversarial attack, backdoor attack and Byzantine attack in federated learning. A new classification method is proposed, and the deficiency of adversarial attack in previous work is supplemented. In addition, this paper studies the multi-level defense system against these attacks at the same time, and puts forward the problems and directions to be solved in the research of federation learning robustness in the future.